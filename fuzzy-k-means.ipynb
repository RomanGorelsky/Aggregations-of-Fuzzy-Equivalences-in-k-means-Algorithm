{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99cf5ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: ucimlrepo in ./.venv/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (3.1.6)\n",
      "Collecting dataframe_image\n",
      "  Downloading dataframe_image-0.2.7-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in ./.venv/lib/python3.10/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2) (3.0.3)\n",
      "Collecting nbconvert>=5 (from dataframe_image)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting aiohttp>=3.10.2 (from dataframe_image)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting requests (from dataframe_image)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting mistune (from dataframe_image)\n",
      "  Downloading mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting lxml (from dataframe_image)\n",
      "  Downloading lxml-6.0.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting beautifulsoup4 (from dataframe_image)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting cssutils (from dataframe_image)\n",
      "  Downloading cssutils-2.11.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting playwright (from dataframe_image)\n",
      "  Downloading playwright-1.57.0-py3-none-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting cssselect (from dataframe_image)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.2->dataframe_image)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp>=3.10.2->dataframe_image) (4.15.0)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp>=3.10.2->dataframe_image)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert>=5->dataframe_image)\n",
      "  Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting defusedxml (from nbconvert>=5->dataframe_image)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in ./.venv/lib/python3.10/site-packages (from nbconvert>=5->dataframe_image) (5.9.1)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=5->dataframe_image)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=5->dataframe_image)\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert>=5->dataframe_image)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=5->dataframe_image)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pygments>=2.4.1 in ./.venv/lib/python3.10/site-packages (from nbconvert>=5->dataframe_image) (2.19.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.10/site-packages (from nbconvert>=5->dataframe_image) (5.14.3)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->dataframe_image)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=5->dataframe_image)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert>=5->dataframe_image) (4.5.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert>=5->dataframe_image) (8.6.3)\n",
      "Requirement already satisfied: pyzmq>=23.0 in ./.venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=5->dataframe_image) (6.5.2)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert>=5->dataframe_image)\n",
      "  Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7->nbconvert>=5->dataframe_image)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=5->dataframe_image)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=5->dataframe_image)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7->nbconvert>=5->dataframe_image)\n",
      "  Using cached rpds_py-0.30.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->dataframe_image)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting more-itertools (from cssutils->dataframe_image)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting pyee<14,>=13 (from playwright->dataframe_image)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting greenlet<4.0.0,>=3.1.1 (from playwright->dataframe_image)\n",
      "  Downloading greenlet-3.3.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->dataframe_image)\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->dataframe_image)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading dataframe_image-0.2.7-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl (489 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading mistune-3.1.4-py3-none-any.whl (53 kB)\n",
      "Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl (47 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.30.0-cp310-cp310-macosx_11_0_arm64.whl (359 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading cssutils-2.11.1-py3-none-any.whl (385 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading lxml-6.0.2-cp310-cp310-macosx_10_9_universal2.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading playwright-1.57.0-py3-none-macosx_11_0_arm64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.3.0-cp310-cp310-macosx_11_0_universal2.whl (273 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl (209 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, urllib3, tinycss2, soupsieve, rpds-py, pyee, propcache, pandocfilters, multidict, more-itertools, mistune, lxml, jupyterlab-pygments, idna, greenlet, frozenlist, defusedxml, cssselect, charset_normalizer, bleach, attrs, async-timeout, aiohappyeyeballs, yarl, requests, referencing, playwright, cssutils, beautifulsoup4, aiosignal, jsonschema-specifications, aiohttp, jsonschema, nbformat, nbclient, nbconvert, dataframe_image\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/38\u001b[0m [dataframe_image] [aiohttp]ht]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.4.0 beautifulsoup4-4.14.3 bleach-6.3.0 charset_normalizer-3.4.4 cssselect-1.3.0 cssutils-2.11.1 dataframe_image-0.2.7 defusedxml-0.7.1 fastjsonschema-2.21.2 frozenlist-1.8.0 greenlet-3.3.0 idna-3.11 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyterlab-pygments-0.3.0 lxml-6.0.2 mistune-3.1.4 more-itertools-10.8.0 multidict-6.7.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 pandocfilters-1.5.1 playwright-1.57.0 propcache-0.4.1 pyee-13.0.0 referencing-0.37.0 requests-2.32.5 rpds-py-0.30.0 soupsieve-2.8 tinycss2-1.4.0 urllib3-2.6.2 webencodings-0.5.1 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy matplotlib pandas scikit-learn seaborn ucimlrepo seaborn jinja2 dataframe_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "25289dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_blobs, make_moons, make_circles\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from typing import Callable\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d8728b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyEquivalenceKMeans:\n",
    "    def __init__(self, n_clusters: int = 3, \n",
    "                 E: str = 'E_GG',\n",
    "                 A: str = 'power_mean',\n",
    "                 p: float = 1,\n",
    "                 max_iter: int = 100,\n",
    "                 random_state: int = 42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.E_name = E\n",
    "        self.A_name = A\n",
    "        self.p = p\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.E = self._get_fuzzy_equivalence(E)\n",
    "        self.A = self._get_aggregation(A)\n",
    "        \n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.clusters = None\n",
    "        \n",
    "    def _get_fuzzy_equivalence(self, E_name: str) -> Callable:\n",
    "\n",
    "        if E_name == 'E_LK':\n",
    "            return self._E_LK\n",
    "        elif E_name == 'E_GG':\n",
    "            return self._E_GG\n",
    "        elif E_name == 'E_GD':\n",
    "            return self._E_GD\n",
    "        elif E_name == 'E_FD':\n",
    "            return self._E_FD\n",
    "        elif E_name == 'E_LK_R':\n",
    "            return self._E_LK_R\n",
    "        elif E_name == 'E_GD_R':\n",
    "            return self._E_GD_R\n",
    "        elif E_name == 'E_FD_R':\n",
    "            return self._E_FD_R\n",
    "        elif E_name == 'E_3':\n",
    "            return self._E_3\n",
    "        elif E_name == 'E_4':\n",
    "            return self._E_4\n",
    "        elif E_name == 'E_5':\n",
    "            return self._E_5\n",
    "        elif E_name == 'E_6':\n",
    "            return self._E_6\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown fuzzy equivalence function: {E_name}\")\n",
    "    \n",
    "    def _get_aggregation(self, A_name: str) -> Callable:\n",
    "\n",
    "        if A_name == 'A2':\n",
    "            return lambda x: self._power_mean(x, p = self.p)\n",
    "        \n",
    "        elif A_name == 'A3':\n",
    "            return self._minimum\n",
    "        \n",
    "        elif A_name == 'A4':\n",
    "            return self._maximum\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation function: {A_name}\")\n",
    "    \n",
    "    def _E_LK(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_LK(x,y) = 1 - |x - y|\"\"\"\n",
    "        return 1 - np.abs(x - y)\n",
    "    \n",
    "    def _E_GG(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_GG(x,y) = min(x, y)/max(x, y) for x ≠ y, 1 for x = y\"\"\"\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            result = np.where(x == y, 1.0, np.minimum(x, y) / np.maximum(x, y))\n",
    "            # Handle division by zero\n",
    "            result = np.nan_to_num(result, nan=1.0, posinf=1.0, neginf=0.0)\n",
    "        return result\n",
    "    \n",
    "    def _E_GD(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_GD(x,y) = min(x,y) for x ≠ y, 1 for x = y\"\"\"\n",
    "        return np.where(x == y, 1.0, np.minimum(x, y))\n",
    "    \n",
    "    def _E_FD(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        E_FD(x,y) = max(1 - y, x) for x < y, max(1 - x, y) for y < x, 1 for x = y\n",
    "        \"\"\"\n",
    "        return np.where(x == y, 1.0, np.where(x < y, np.maximum(1 - y, x), np.maximum(1 - x, y)))\n",
    "    \n",
    "    def _E_LK_R(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E^R_LK(x,y) = (E_LK(x,y))^2\"\"\"\n",
    "        return self._E_LK(x, y) ** 2\n",
    "    \n",
    "    def _E_GD_R(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E^R_GD(x,y) = E_GD(x,y) * (2 - E_GD(x,y))\"\"\"\n",
    "        e_gd = self._E_GD(x, y)\n",
    "        return e_gd * (2 - e_gd)\n",
    "    \n",
    "    def _E_FD_R(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E^R_FD(x,y) piecewise function\"\"\"\n",
    "        e_fd = self._E_FD(x, y)\n",
    "        return np.where(e_fd >= 0.5, 1 - 2 * ((1 - e_fd) ** 2), 2 * (e_fd ** 2))\n",
    "    \n",
    "    def _E_3(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_3(x,y) = 2*min(x,y)/(x+y) for x+y>0, otherwise 1\"\"\"\n",
    "        denominator = x + y\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            result = np.where(denominator > 0, \n",
    "                            2 * np.minimum(x, y) / denominator, \n",
    "                            1.0)\n",
    "            result = np.nan_to_num(result, nan=1.0)\n",
    "        return np.clip(result, 0, 1)\n",
    "    \n",
    "    def _E_4(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_4(x,y) = 2*x*y/(x^2+y^2) for x+y>0, otherwise 1\"\"\"\n",
    "        denominator = x**2 + y**2\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            result = np.where((x + y) > 0, \n",
    "                            2 * x * y / denominator, \n",
    "                            1.0)\n",
    "            result = np.nan_to_num(result, nan=1.0, posinf=1.0, neginf=0.0)\n",
    "        return np.clip(result, 0, 1)\n",
    "    \n",
    "    def _E_5(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_5(x,y) = 2*min(x^2,y^2)/(x^2+y^2) for x+y>0, otherwise 1\"\"\"\n",
    "        denominator = x**2 + y**2\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            result = np.where((x + y) > 0, \n",
    "                            2 * np.minimum(x**2, y**2) / denominator, \n",
    "                            1.0)\n",
    "            result = np.nan_to_num(result, nan=1.0, posinf=1.0, neginf=0.0)\n",
    "        return np.clip(result, 0, 1)\n",
    "    \n",
    "    def _E_6(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"E_6(x,y) = (1 - |x-y|)/(1+|x-y|)\"\"\"\n",
    "        numerator = 1 - np.abs(x - y)\n",
    "        denominator = 1 + np.abs(x - y)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            result = numerator / denominator\n",
    "            result = np.nan_to_num(result, nan=1.0)\n",
    "        return np.clip(result, 0, 1)\n",
    "    \n",
    "    def _power_mean(self, values: np.ndarray, p: float = 2) -> np.floating:\n",
    "        \"\"\"A2: Power mean of values with parameter p\"\"\"\n",
    "        if p == 0:\n",
    "            return np.prod(values) ** (1/len(values))\n",
    "        return (np.mean(values ** p)) ** (1/p)\n",
    "    \n",
    "    def _minimum(self, values: np.ndarray) -> float:\n",
    "        \"\"\"A3: Minimum of values\"\"\"\n",
    "        return np.min(values)\n",
    "    \n",
    "    def _maximum(self, values: np.ndarray) -> float:\n",
    "        \"\"\"A4: Maximum of values\"\"\"\n",
    "        return np.max(values)\n",
    "    \n",
    "    def _initialize_centroids(self, X: np.ndarray) -> None:\n",
    "        \"\"\"Initialize centroids randomly from data points.\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        indices = np.random.choice(X.shape[0], self.n_clusters, replace=False)\n",
    "        self.centroids = X[indices].copy()\n",
    "    \n",
    "    def _normalize_data(self, X: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        X_norm = X.copy().astype(float)\n",
    "        for i in range(X.shape[1]):\n",
    "            min_val = np.min(X[:, i])\n",
    "            max_val = np.max(X[:, i])\n",
    "            if max_val > min_val:\n",
    "                X_norm[:, i] = (X[:, i] - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                X_norm[:, i] = 0.5\n",
    "        return X_norm\n",
    "    \n",
    "    def fit(self, X: np.ndarray) -> 'FuzzyEquivalenceKMeans':\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        X_norm = self._normalize_data(X)\n",
    "        self._initialize_centroids(X)\n",
    "        centroids_norm = self._normalize_data(self.centroids)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "\n",
    "            old_centroids = self.centroids.copy()\n",
    "            labels = np.zeros(n_samples, dtype=int)\n",
    "            \n",
    "            for i in range(n_samples):\n",
    "                closeness_values = []\n",
    "                \n",
    "                for j in range(self.n_clusters):\n",
    "                    \n",
    "                    eq_values = self.E(X_norm[i], centroids_norm[j])\n",
    "                    closeness = self.A(eq_values)\n",
    "                    closeness_values.append(closeness)\n",
    "\n",
    "                labels[i] = np.argmax(closeness_values)\n",
    "            \n",
    "            self.labels = labels\n",
    "            \n",
    "            for j in range(self.n_clusters):\n",
    "                cluster_points = X[labels == j]\n",
    "                if len(cluster_points) > 0:\n",
    "                    self.centroids[j] = np.mean(cluster_points, axis=0)\n",
    "            \n",
    "            centroids_norm = self._normalize_data(self.centroids)\n",
    "            \n",
    "            if np.allclose(old_centroids, self.centroids, rtol=1e-5):\n",
    "                print(f\"Converged at iteration {iteration + 1}\")\n",
    "                break\n",
    "            \n",
    "            if iteration == self.max_iter - 1:\n",
    "                print(f\"Reached maximum iterations ({self.max_iter})\")\n",
    "        \n",
    "        self.clusters = {}\n",
    "        for j in range(self.n_clusters):\n",
    "            self.clusters[j] = {\n",
    "                'center': self.centroids[j],\n",
    "                'points': X[self.labels == j]\n",
    "            }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if self.centroids is None:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        \n",
    "        X_norm = self._normalize_data(X)\n",
    "        centroids_norm = self._normalize_data(self.centroids)\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        labels = np.zeros(n_samples, dtype=int)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            closeness_values = []\n",
    "            \n",
    "            for j in range(self.n_clusters):\n",
    "                eq_values = self.E(X_norm[i], centroids_norm[j])\n",
    "                closeness = self.A(eq_values)\n",
    "                closeness_values.append(closeness)\n",
    "            \n",
    "            labels[i] = np.argmax(closeness_values)\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def fit_predict(self, X: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        self.fit(X)\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5ef7fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_silhouette_score(X: np.ndarray, labels: np.ndarray,\n",
    "                                 model: 'FuzzyEquivalenceKMeans') -> float:\n",
    "    \"\"\"\n",
    "    Simplified version of silhouette score using distance-like measure.\n",
    "    Uses 1 - closeness as distance.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    if n_clusters <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Normalize data\n",
    "    X_norm = model._normalize_data(X)\n",
    "    centroids_norm = model._normalize_data(model.centroids)\n",
    "    \n",
    "    # Compute distance matrix using 1 - closeness\n",
    "    distance_matrix = np.zeros((n_samples, n_clusters))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_clusters):\n",
    "            eq_values = model.E(X_norm[i], centroids_norm[j])\n",
    "            closeness = model.A(eq_values)\n",
    "            distance_matrix[i, j] = 1 - closeness\n",
    "    \n",
    "    silhouette_vals = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        cluster_i = labels[i]\n",
    "        \n",
    "        # a(i): average distance to points in same cluster\n",
    "        mask_same = (labels == cluster_i)\n",
    "        mask_same[i] = False\n",
    "        if np.sum(mask_same) > 0:\n",
    "            a = np.mean(distance_matrix[i, cluster_i] + distance_matrix[mask_same, cluster_i])\n",
    "        else:\n",
    "            a = 0\n",
    "        \n",
    "        # b(i): minimum average distance to other clusters\n",
    "        b = np.inf\n",
    "        for cluster_j in range(n_clusters):\n",
    "            if cluster_j != cluster_i:\n",
    "                mask_other = (labels == cluster_j)\n",
    "                if np.sum(mask_other) > 0:\n",
    "                    avg_dist = np.mean(distance_matrix[i, cluster_j] + distance_matrix[mask_other, cluster_j])\n",
    "                    b = min(b, avg_dist)\n",
    "        \n",
    "        if np.isinf(b):\n",
    "            b = 0\n",
    "        \n",
    "        if max(a, b) > 0:\n",
    "            silhouette_vals[i] = (b - a) / max(a, b)\n",
    "    \n",
    "    return np.mean(silhouette_vals)\n",
    "\n",
    "\n",
    "def fuzzy_davies_bouldin_score(X: np.ndarray, labels: np.ndarray,\n",
    "                              model: 'FuzzyEquivalenceKMeans') -> float:\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    if n_clusters <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    X_norm = model._normalize_data(X)\n",
    "    centroids_norm = model._normalize_data(model.centroids)\n",
    "    \n",
    "    S = np.zeros(n_clusters)\n",
    "    cluster_sizes = np.zeros(n_clusters, dtype=int)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        cluster_i = labels[i]\n",
    "        cluster_sizes[cluster_i] += 1\n",
    "        \n",
    "        eq_values = model.E(X_norm[i], centroids_norm[cluster_i])\n",
    "        closeness = model.A(eq_values)\n",
    "        S[cluster_i] += 1 - closeness\n",
    "    \n",
    "    for j in range(n_clusters):\n",
    "        if cluster_sizes[j] > 0:\n",
    "            S[j] = S[j] / cluster_sizes[j]\n",
    "        else:\n",
    "            S[j] = 0\n",
    "    \n",
    "    M = np.zeros((n_clusters, n_clusters))\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(n_clusters):\n",
    "            if i != j:\n",
    "                eq_values = model.E(centroids_norm[i], centroids_norm[j])\n",
    "                closeness = model.A(eq_values)\n",
    "                M[i, j] = 1 - closeness\n",
    "    \n",
    "    R = np.zeros((n_clusters, n_clusters))\n",
    "    for i in range(n_clusters):\n",
    "        for j in range(n_clusters):\n",
    "            if i != j:\n",
    "                R[i, j] = (S[i] + S[j]) / M[i, j]\n",
    "    \n",
    "    D = np.zeros(n_clusters)\n",
    "    for i in range(n_clusters):\n",
    "        if np.any(R[i, :] > 0):\n",
    "            D[i] = np.max(R[i, :])\n",
    "    \n",
    "    return np.mean(D)\n",
    "\n",
    "def fuzzy_calinski_harabasz_score(X: np.ndarray, labels: np.ndarray,\n",
    "                                 model: 'FuzzyEquivalenceKMeans') -> float:\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    \n",
    "    if n_clusters <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    X_norm = model._normalize_data(X)\n",
    "    centroids_norm = model._normalize_data(model.centroids)\n",
    "    overall_centroid_norm = np.mean(X_norm, axis=0)\n",
    "    \n",
    "    total_dispersion = 0\n",
    "    for i in range(n_samples):\n",
    "        eq_values = model.E(X_norm[i], overall_centroid_norm)\n",
    "        closeness = model.A(eq_values)\n",
    "        total_dispersion += 1 - closeness\n",
    "    \n",
    "    within_dispersion = 0\n",
    "    cluster_sizes = np.zeros(n_clusters, dtype=int)\n",
    "    \n",
    "    for j in range(n_clusters):\n",
    "        mask = labels == j\n",
    "        cluster_points = X_norm[mask]\n",
    "        cluster_sizes[j] = len(cluster_points)\n",
    "        \n",
    "        for i in range(len(cluster_points)):\n",
    "            eq_values = model.E(cluster_points[i], centroids_norm[j])\n",
    "            closeness = model.A(eq_values)\n",
    "            within_dispersion += 1 - closeness\n",
    "    \n",
    "    between_dispersion = 0\n",
    "    for j in range(n_clusters):\n",
    "        if cluster_sizes[j] > 0:\n",
    "            eq_values = model.E(centroids_norm[j], overall_centroid_norm)\n",
    "            closeness = model.A(eq_values)\n",
    "            between_dispersion += cluster_sizes[j] * (1 - closeness)\n",
    "    \n",
    "    if within_dispersion == 0 or n_samples - n_clusters == 0:\n",
    "        return float('inf') if between_dispersion > 0 else 0.0\n",
    "    \n",
    "    score = (between_dispersion / (n_clusters - 1)) / (within_dispersion / (n_samples - n_clusters))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "524006df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_datasets():\n",
    "\n",
    "    datasets = {}\n",
    "    print(\"Loading sklearn datasets...\")\n",
    "    \n",
    "    # Iris dataset\n",
    "    iris = load_iris()\n",
    "    X_iris = iris.data\n",
    "    y_iris = iris.target\n",
    "    datasets['Iris'] = {'X': X_iris, 'y': y_iris, 'n_clusters': 3, 'description': 'Iris flowers dataset (150 samples, 4 features)'}\n",
    "    \n",
    "    # Wine dataset\n",
    "    wine = load_wine()\n",
    "    X_wine = wine.data\n",
    "    y_wine = wine.target\n",
    "    datasets['Wine'] = {'X': X_wine, 'y': y_wine, 'n_clusters': 3, 'description': 'Wine chemical analysis dataset (178 samples, 13 features)'}\n",
    "    \n",
    "    # Breast cancer dataset\n",
    "    cancer = load_breast_cancer()\n",
    "    X_cancer = cancer.data\n",
    "    y_cancer = cancer.target\n",
    "    datasets['Breast_Cancer'] = {'X': X_cancer, 'y': y_cancer, 'n_clusters': 2, 'description': 'Breast cancer diagnostic dataset (569 samples, 30 features)'}\n",
    "    \n",
    "    # Synthetic datasets\n",
    "    print(\"Generating synthetic datasets...\")\n",
    "    \n",
    "    # Blobs dataset\n",
    "    X_blobs, y_blobs = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)\n",
    "    datasets['Blobs'] = {'X': X_blobs, 'y': y_blobs, 'n_clusters': 4, 'description': 'Synthetic Gaussian blobs (300 samples, 2 features)'}\n",
    "    \n",
    "    # Moons dataset\n",
    "    X_moons, y_moons = make_moons(n_samples=300, noise=0.1, random_state=42)\n",
    "    datasets['Moons'] = {'X': X_moons, 'y': y_moons, 'n_clusters': 2, 'description': 'Two interleaving moons (300 samples, 2 features)'}\n",
    "    \n",
    "    # Circles dataset\n",
    "    X_circles, y_circles = make_circles(n_samples=300, noise=0.05, factor=0.5, random_state=42)\n",
    "    datasets['Circles'] = {'X': X_circles, 'y': y_circles, 'n_clusters': 2, 'description': 'Two concentric circles (300 samples, 2 features)'}\n",
    "    \n",
    "    # 2. UCI datasets placeholder - will be loaded if files exist\n",
    "    print(\"\\nNote: UCI datasets will be loaded if files exist in 'data/' folder\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "def load_uci_datasets():\n",
    "\n",
    "    uci_datasets = {}\n",
    "    \n",
    "    # List of UCI datasets and their expected files\n",
    "    uci_files = {\n",
    "        'Wholesale_Customers': 'data/Wholesale_customers.csv',\n",
    "        'Heart_Failure': 'data/heart_failure_clinical_records.csv',\n",
    "        'Seeds': 'data/seeds_dataset.csv',\n",
    "        'Absenteeism': 'data/Absenteeism_at_work.csv'\n",
    "    }\n",
    "    \n",
    "    for dataset_name, file_path in uci_files.items():\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                print(f\"Loading {dataset_name} from {file_path}...\")\n",
    "                \n",
    "                if dataset_name == 'Online_Retail':\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Select numerical columns\n",
    "                    numeric_cols = ['Quantity', 'UnitPrice']\n",
    "                    df = df[numeric_cols].dropna()\n",
    "                    X = df.values[:1000]  # Use subset for faster testing\n",
    "                    n_clusters = 5\n",
    "                    \n",
    "                elif dataset_name == 'Wholesale_Customers':\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Use all columns except Channel and Region if they exist\n",
    "                    if 'Channel' in df.columns:\n",
    "                        df = df.drop(['Channel', 'Region'], axis=1)\n",
    "                    X = df.values\n",
    "                    n_clusters = 3\n",
    "                    \n",
    "                elif dataset_name == 'Heart_Failure':\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    X = df.drop('DEATH_EVENT', axis=1).values\n",
    "                    n_clusters = 2\n",
    "                    \n",
    "                elif dataset_name == 'Seeds':\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    X = df.iloc[:, :-1].values\n",
    "                    n_clusters = 3\n",
    "                    \n",
    "                elif dataset_name == 'Absenteeism':\n",
    "                    df = pd.read_csv(file_path, sep=';')\n",
    "                    # Select numerical columns\n",
    "                    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                    X = df[numeric_cols].values[:200]  # Use subset\n",
    "                    n_clusters = 4\n",
    "                \n",
    "                # For datasets without true labels, create pseudo-labels for n_clusters determination\n",
    "                if dataset_name in ['Online_Retail', 'Wholesale_Customers', 'Absenteeism']:\n",
    "                    from sklearn.cluster import KMeans\n",
    "                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "                    y = kmeans.fit_predict(X)\n",
    "                else:\n",
    "                    # For datasets with true labels\n",
    "                    y = None\n",
    "                \n",
    "                uci_datasets[dataset_name] = {\n",
    "                    'X': X,\n",
    "                    'y': y,\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'description': f'{dataset_name} dataset ({X.shape[0]} samples, {X.shape[1]} features)'\n",
    "                }\n",
    "                \n",
    "                print(f\"  ✓ Loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error loading {dataset_name}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"  ⚠ {dataset_name} file not found: {file_path}\")\n",
    "    \n",
    "    return uci_datasets\n",
    "\n",
    "\n",
    "def run_all_combinations_on_dataset(X, dataset_name, n_clusters=3, max_iter=100, random_state=42, p_values=[0.1, 1, 4]):\n",
    "    \n",
    "    fuzzy_equivs = [\n",
    "        'E_LK', 'E_GG', 'E_GD', 'E_FD',\n",
    "        'E_LK_R', 'E_GG_R', 'E_GD_R', 'E_FD_R',\n",
    "        'E_3', 'E_4', 'E_5', 'E_6'\n",
    "    ]\n",
    "    \n",
    "    aggregations = ['A2', 'A3', 'A4']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing dataset: {dataset_name}\")\n",
    "    print(f\"Shape: {X.shape}, Clusters: {n_clusters}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    total_combinations = len(fuzzy_equivs) * len(aggregations)\n",
    "    if 'A2' in aggregations:\n",
    "        total_combinations += len(fuzzy_equivs) * (len(p_values) - 1)\n",
    "    \n",
    "    print(f\"Testing {total_combinations} combinations...\")\n",
    "    \n",
    "    print(\"\\n1. Running Standard KMeans for baseline comparison...\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, \n",
    "                   random_state=random_state, \n",
    "                   n_init=10)\n",
    "    \n",
    "    kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    if len(np.unique(kmeans_labels)) > 1:\n",
    "        standard_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
    "        standard_db = davies_bouldin_score(X_scaled, kmeans_labels)\n",
    "        standard_ch = calinski_harabasz_score(X_scaled, kmeans_labels)\n",
    "    else:\n",
    "        standard_silhouette = 0\n",
    "        standard_db = float('inf')\n",
    "        standard_ch = 0\n",
    "    \n",
    "    results.append({\n",
    "        'dataset': dataset_name,\n",
    "        'E': 'Euclidean',\n",
    "        'A': 'Mean',\n",
    "        'p': None,\n",
    "        'silhouette_score': standard_silhouette,\n",
    "        'davies_bouldin_score': standard_db,\n",
    "        'calinski_harabasz_score': standard_ch,\n",
    "        'n_clusters_found': len(np.unique(kmeans_labels)),\n",
    "        'method': 'Standard_KMeans',\n",
    "        'inertia': kmeans.inertia_\n",
    "    })\n",
    "    \n",
    "    print(f\"   Standard KMeans Results:\")\n",
    "    print(f\"     Silhouette: {standard_silhouette:.4f}\")\n",
    "    print(f\"     Davies-Bouldin: {standard_db:.4f}\")\n",
    "    print(f\"     Calinski-Harabasz: {standard_ch:.4f}\")\n",
    "    print(f\"     Inertia: {kmeans.inertia_:.4f}\")\n",
    "    print(f\"\\n2. Running Fuzzy Equivalence KMeans combinations...\")\n",
    "    \n",
    "    current = 0\n",
    "\n",
    "    for E_name in fuzzy_equivs:\n",
    "        for A_name in aggregations:\n",
    "            if A_name == 'A2':\n",
    "                for p in p_values:\n",
    "                    current += 1\n",
    "                    combination_id = f\"{E_name}_{A_name}_p{p}\"\n",
    "                    \n",
    "                    try:\n",
    "                        model = FuzzyEquivalenceKMeans(\n",
    "                            n_clusters=n_clusters,\n",
    "                            E=E_name,\n",
    "                            A=A_name,\n",
    "                            p=p,\n",
    "                            max_iter=max_iter,\n",
    "                            random_state=random_state\n",
    "                        )\n",
    "                        \n",
    "                        labels = model.fit_predict(X)\n",
    "                        \n",
    "                        n_clusters_found = len(np.unique(labels))\n",
    "                        \n",
    "                        if n_clusters_found > 1:\n",
    "                            sil_score = fuzzy_silhouette_score(X, labels, model)\n",
    "                            db_score = fuzzy_davies_bouldin_score(X, labels, model)\n",
    "                            ch_score = fuzzy_calinski_harabasz_score(X, labels, model)\n",
    "                        else:\n",
    "                            sil_score = 0\n",
    "                            db_score = float('inf')\n",
    "                            ch_score = 0\n",
    "                        \n",
    "                        results.append({\n",
    "                            'dataset': dataset_name,\n",
    "                            'E': E_name,\n",
    "                            'A': A_name,\n",
    "                            'p': p,\n",
    "                            'silhouette_score': sil_score,\n",
    "                            'davies_bouldin_score': db_score,\n",
    "                            'calinski_harabasz_score': ch_score,\n",
    "                            'n_clusters_found': n_clusters_found,\n",
    "                            'method': 'Fuzzy_Equivalence',\n",
    "                            'inertia': None  # Fuzzy method doesn't have inertia\n",
    "                        })\n",
    "                        \n",
    "                        if current % 10 == 0:\n",
    "                            print(f\"  Progress: {current}/{total_combinations} | Current: {combination_id}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        results.append({\n",
    "                            'dataset': dataset_name,\n",
    "                            'E': E_name,\n",
    "                            'A': A_name,\n",
    "                            'p': p,\n",
    "                            'silhouette_score': 0,\n",
    "                            'davies_bouldin_score': float('inf'),\n",
    "                            'calinski_harabasz_score': 0,\n",
    "                            'n_clusters_found': 0,\n",
    "                            'method': 'Fuzzy_Equivalence',\n",
    "                            'inertia': None,\n",
    "                            'error': str(e)\n",
    "                        })\n",
    "            else:\n",
    "                current += 1\n",
    "                combination_id = f\"{E_name}_{A_name}\"\n",
    "                \n",
    "                try:\n",
    "                    model = FuzzyEquivalenceKMeans(\n",
    "                        n_clusters=n_clusters,\n",
    "                        E=E_name,\n",
    "                        A=A_name,\n",
    "                        p=1,\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=random_state\n",
    "                    )\n",
    "                    \n",
    "                    labels = model.fit_predict(X)\n",
    "                    n_clusters_found = len(np.unique(labels))\n",
    "                    \n",
    "                    if n_clusters_found > 1:\n",
    "                        sil_score = fuzzy_silhouette_score(X, labels, model)\n",
    "                        db_score = fuzzy_davies_bouldin_score(X, labels, model)\n",
    "                        ch_score = fuzzy_calinski_harabasz_score(X, labels, model)\n",
    "                    else:\n",
    "                        sil_score = 0\n",
    "                        db_score = float('inf')\n",
    "                        ch_score = 0\n",
    "                    \n",
    "                    results.append({\n",
    "                        'dataset': dataset_name,\n",
    "                        'E': E_name,\n",
    "                        'A': A_name,\n",
    "                        'p': None,\n",
    "                        'silhouette_score': sil_score,\n",
    "                        'davies_bouldin_score': db_score,\n",
    "                        'calinski_harabasz_score': ch_score,\n",
    "                        'n_clusters_found': n_clusters_found,\n",
    "                        'method': 'Fuzzy_Equivalence',\n",
    "                        'inertia': None\n",
    "                    })\n",
    "                    \n",
    "                    if current % 10 == 0:\n",
    "                        print(f\"  Progress: {current}/{total_combinations} | Current: {combination_id}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    results.append({\n",
    "                        'dataset': dataset_name,\n",
    "                        'E': E_name,\n",
    "                        'A': A_name,\n",
    "                        'p': None,\n",
    "                        'silhouette_score': 0,\n",
    "                        'davies_bouldin_score': float('inf'),\n",
    "                        'calinski_harabasz_score': 0,\n",
    "                        'n_clusters_found': 0,\n",
    "                        'method': 'Fuzzy_Equivalence',\n",
    "                        'inertia': None,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    def get_combination_name(row):\n",
    "        if row['method'] == 'Standard_KMeans':\n",
    "            return 'Standard_KMeans'\n",
    "        elif pd.isna(row['p']) or row['p'] is None:\n",
    "            return f\"{row['E']}_{row['A']}\"\n",
    "        else:\n",
    "            return f\"{row['E']}_{row['A']}_p{row['p']}\"\n",
    "    \n",
    "    results_df['combination'] = results_df.apply(get_combination_name, axis=1)\n",
    "    \n",
    "    print(f\"\\n✓ Completed {len(results_df)} runs for {dataset_name}\")\n",
    "    print(f\"  - Standard KMeans: 1 run\")\n",
    "    print(f\"  - Fuzzy Equivalence: {len(results_df) - 1} runs\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPARISON ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    fuzzy_results = results_df[results_df['method'] == 'Fuzzy_Equivalence']\n",
    "    successful_fuzzy = fuzzy_results[fuzzy_results['n_clusters_found'] > 0]\n",
    "    \n",
    "    if len(successful_fuzzy) > 0:\n",
    "        best_fuzzy_sil = successful_fuzzy.loc[successful_fuzzy['silhouette_score'].idxmax()]\n",
    "        best_fuzzy_db = successful_fuzzy.loc[successful_fuzzy['davies_bouldin_score'].idxmin()]\n",
    "        best_fuzzy_ch = successful_fuzzy.loc[successful_fuzzy['calinski_harabasz_score'].idxmax()]\n",
    "        \n",
    "        standard_row = results_df[results_df['method'] == 'Standard_KMeans'].iloc[0]\n",
    "        \n",
    "        print(f\"\\nStandard KMeans vs Best Fuzzy Equivalence:\")\n",
    "        print(f\"{'-'*50}\")\n",
    "        \n",
    "        print(f\"\\nSilhouette Score:\")\n",
    "        print(f\"  Standard KMeans: {standard_row['silhouette_score']:.4f}\")\n",
    "        print(f\"  Best Fuzzy: {best_fuzzy_sil['silhouette_score']:.4f} ({best_fuzzy_sil['combination']})\")\n",
    "        if best_fuzzy_sil['silhouette_score'] > standard_row['silhouette_score']:\n",
    "            improvement = ((best_fuzzy_sil['silhouette_score'] - standard_row['silhouette_score']) / \n",
    "                          abs(standard_row['silhouette_score']) * 100)\n",
    "            print(f\"  ✅ Fuzzy better by: {improvement:+.2f}%\")\n",
    "        else:\n",
    "            print(f\"  ❌ Standard better or equal\")\n",
    "        \n",
    "        print(f\"\\nDavies-Bouldin Score (lower is better):\")\n",
    "        print(f\"  Standard KMeans: {standard_row['davies_bouldin_score']:.4f}\")\n",
    "        print(f\"  Best Fuzzy: {best_fuzzy_db['davies_bouldin_score']:.4f} ({best_fuzzy_db['combination']})\")\n",
    "        if best_fuzzy_db['davies_bouldin_score'] < standard_row['davies_bouldin_score']:\n",
    "            improvement = ((standard_row['davies_bouldin_score'] - best_fuzzy_db['davies_bouldin_score']) / \n",
    "                          standard_row['davies_bouldin_score'] * 100)\n",
    "            print(f\"  ✅ Fuzzy better by: {improvement:+.2f}%\")\n",
    "        else:\n",
    "            print(f\"  ❌ Standard better or equal\")\n",
    "        \n",
    "        print(f\"\\nCalinski-Harabasz Score:\")\n",
    "        print(f\"  Standard KMeans: {standard_row['calinski_harabasz_score']:.4f}\")\n",
    "        print(f\"  Best Fuzzy: {best_fuzzy_ch['calinski_harabasz_score']:.4f} ({best_fuzzy_ch['combination']})\")\n",
    "        if best_fuzzy_ch['calinski_harabasz_score'] > standard_row['calinski_harabasz_score']:\n",
    "            improvement = ((best_fuzzy_ch['calinski_harabasz_score'] - standard_row['calinski_harabasz_score']) / \n",
    "                          abs(standard_row['calinski_harabasz_score']) * 100)\n",
    "            print(f\"  ✅ Fuzzy better by: {improvement:+.2f}%\")\n",
    "        else:\n",
    "            print(f\"  ❌ Standard better or equal\")\n",
    "        \n",
    "        fuzzy_beats_standard_sil = len(successful_fuzzy[successful_fuzzy['silhouette_score'] > standard_row['silhouette_score']])\n",
    "        fuzzy_beats_standard_db = len(successful_fuzzy[successful_fuzzy['davies_bouldin_score'] < standard_row['davies_bouldin_score']])\n",
    "        fuzzy_beats_standard_ch = len(successful_fuzzy[successful_fuzzy['calinski_harabasz_score'] > standard_row['calinski_harabasz_score']])\n",
    "        \n",
    "        print(f\"\\nSummary of fuzzy methods beating standard:\")\n",
    "        print(f\"  Silhouette: {fuzzy_beats_standard_sil}/{len(successful_fuzzy)} methods\")\n",
    "        print(f\"  Davies-Bouldin: {fuzzy_beats_standard_db}/{len(successful_fuzzy)} methods\")\n",
    "        print(f\"  Calinski-Harabasz: {fuzzy_beats_standard_ch}/{len(successful_fuzzy)} methods\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def analyze_and_save_results(results_df, dataset_name):\n",
    "    \n",
    "    standard_results = results_df[results_df['method'] == 'Standard_KMeans']\n",
    "    fuzzy_results = results_df[results_df['method'] == 'Fuzzy_Equivalence']\n",
    "    successful_fuzzy = fuzzy_results[fuzzy_results['n_clusters_found'] > 0].copy()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANALYSIS FOR {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nMETHODS SUMMARY:\")\n",
    "    print(f\"  Standard KMeans: 1 run\")\n",
    "    print(f\"  Fuzzy Equivalence: {len(fuzzy_results)} runs\")\n",
    "    print(f\"  Successful fuzzy runs: {len(successful_fuzzy)}\")\n",
    "    \n",
    "    if len(standard_results) > 0:\n",
    "        std_row = standard_results.iloc[0]\n",
    "        print(f\"\\nSTANDARD KMEANS RESULTS:\")\n",
    "        print(f\"  Silhouette Score: {std_row['silhouette_score']:.4f}\")\n",
    "        print(f\"  Davies-Bouldin Score: {std_row['davies_bouldin_score']:.4f}\")\n",
    "        print(f\"  Calinski-Harabasz Score: {std_row['calinski_harabasz_score']:.4f}\")\n",
    "        if 'inertia' in std_row and pd.notnull(std_row['inertia']):\n",
    "            print(f\"  Inertia (WCSS): {std_row['inertia']:.4f}\")\n",
    "    \n",
    "    if len(successful_fuzzy) > 0:\n",
    "        print(f\"\\nBEST FUZZY EQUIVALENCE RESULTS:\")\n",
    "        \n",
    "        if successful_fuzzy['silhouette_score'].max() > 0:\n",
    "            best_sil = successful_fuzzy.loc[successful_fuzzy['silhouette_score'].idxmax()]\n",
    "            print(f\"\\n  Best Silhouette Score: {best_sil['silhouette_score']:.4f}\")\n",
    "            print(f\"    Combination: {best_sil['combination']}\")\n",
    "            print(f\"    Parameters: E={best_sil['E']}, A={best_sil['A']}, p={best_sil['p']}\")\n",
    "            \n",
    "            # Compare with standard\n",
    "            if len(standard_results) > 0:\n",
    "                std_sil = standard_results.iloc[0]['silhouette_score']\n",
    "                improvement = ((best_sil['silhouette_score'] - std_sil) / abs(std_sil) * 100)\n",
    "                print(f\"    vs Standard KMeans: {improvement:+.2f}%\")\n",
    "        \n",
    "        if successful_fuzzy['davies_bouldin_score'].min() < float('inf'):\n",
    "            best_db = successful_fuzzy.loc[successful_fuzzy['davies_bouldin_score'].idxmin()]\n",
    "            print(f\"\\n  Best Davies-Bouldin Score: {best_db['davies_bouldin_score']:.4f}\")\n",
    "            print(f\"    Combination: {best_db['combination']}\")\n",
    "            print(f\"    Parameters: E={best_db['E']}, A={best_db['A']}, p={best_db['p']}\")\n",
    "            \n",
    "            if len(standard_results) > 0:\n",
    "                std_db = standard_results.iloc[0]['davies_bouldin_score']\n",
    "                improvement = ((std_db - best_db['davies_bouldin_score']) / std_db * 100)\n",
    "                print(f\"    vs Standard KMeans: {improvement:+.2f}% improvement\")\n",
    "        \n",
    "        if successful_fuzzy['calinski_harabasz_score'].max() > 0:\n",
    "            best_ch = successful_fuzzy.loc[successful_fuzzy['calinski_harabasz_score'].idxmax()]\n",
    "            print(f\"\\n  Best Calinski-Harabasz Score: {best_ch['calinski_harabasz_score']:.4f}\")\n",
    "            print(f\"    Combination: {best_ch['combination']}\")\n",
    "            print(f\"    Parameters: E={best_ch['E']}, A={best_ch['A']}, p={best_ch['p']}\")\n",
    "            \n",
    "            if len(standard_results) > 0:\n",
    "                std_ch = standard_results.iloc[0]['calinski_harabasz_score']\n",
    "                improvement = ((best_ch['calinski_harabasz_score'] - std_ch) / abs(std_ch) * 100)\n",
    "                print(f\"    vs Standard KMeans: {improvement:+.2f}%\")\n",
    "        \n",
    "        print(f\"\\nFUZZY METHODS SUMMARY STATISTICS:\")\n",
    "        print(f\"  Average Silhouette Score: {successful_fuzzy['silhouette_score'].mean():.4f}\")\n",
    "        print(f\"  Average Davies-Bouldin Score: {successful_fuzzy['davies_bouldin_score'].mean():.4f}\")\n",
    "        print(f\"  Average Calinski-Harabasz Score: {successful_fuzzy['calinski_harabasz_score'].mean():.1f}\")\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\n💾 Saving results to CSV files...\")\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    full_filename = f'results/full_results_{dataset_name}.csv'\n",
    "    results_df.to_csv(full_filename, index=False)\n",
    "    print(f\"  Full results saved to: {full_filename}\")\n",
    "    \n",
    "    if len(successful_fuzzy) > 0:\n",
    "        top10_fuzzy = successful_fuzzy.sort_values('silhouette_score', ascending=False).head(10)\n",
    "        top10_filename = f'results/top10_fuzzy_{dataset_name}.csv'\n",
    "        top10_fuzzy.to_csv(top10_filename, index=False)\n",
    "        print(f\"  Top 10 fuzzy methods saved to: {top10_filename}\")\n",
    "        \n",
    "        if len(standard_results) > 0:\n",
    "            comparison_data = []\n",
    "            std_row = standard_results.iloc[0]\n",
    "            \n",
    "            for idx, (_, row) in enumerate(top10_fuzzy.iterrows()):\n",
    "                improvement_sil = ((row['silhouette_score'] - std_row['silhouette_score']) / \n",
    "                                  abs(std_row['silhouette_score']) * 100)\n",
    "                improvement_db = ((std_row['davies_bouldin_score'] - row['davies_bouldin_score']) / \n",
    "                                 std_row['davies_bouldin_score'] * 100) if std_row['davies_bouldin_score'] > 0 else 0\n",
    "                improvement_ch = ((row['calinski_harabasz_score'] - std_row['calinski_harabasz_score']) / \n",
    "                                  abs(std_row['calinski_harabasz_score']) * 100)\n",
    "                \n",
    "                comparison_data.append({\n",
    "                    'Rank': idx + 1,\n",
    "                    'Combination': row['combination'],\n",
    "                    'Silhouette_Score': row['silhouette_score'],\n",
    "                    'Silhouette_Improvement_%': improvement_sil,\n",
    "                    'DB_Score': row['davies_bouldin_score'],\n",
    "                    'DB_Improvement_%': improvement_db,\n",
    "                    'CH_Score': row['calinski_harabasz_score'],\n",
    "                    'CH_Improvement_%': improvement_ch,\n",
    "                    'E_Function': row['E'],\n",
    "                    'A_Function': row['A'],\n",
    "                    'p_Value': row['p']\n",
    "                })\n",
    "            \n",
    "            comparison_df = pd.DataFrame(comparison_data)\n",
    "            comparison_df = pd.concat([\n",
    "                pd.DataFrame([{\n",
    "                    'Rank': 'Baseline',\n",
    "                    'Combination': 'Standard_KMeans',\n",
    "                    'Silhouette_Score': std_row['silhouette_score'],\n",
    "                    'Silhouette_Improvement_%': 0,\n",
    "                    'DB_Score': std_row['davies_bouldin_score'],\n",
    "                    'DB_Improvement_%': 0,\n",
    "                    'CH_Score': std_row['calinski_harabasz_score'],\n",
    "                    'CH_Improvement_%': 0,\n",
    "                    'E_Function': 'Euclidean',\n",
    "                    'A_Function': 'Mean',\n",
    "                    'p_Value': None\n",
    "                }]),\n",
    "                comparison_df\n",
    "            ], ignore_index=True)\n",
    "            \n",
    "            comparison_filename = f'results/comparison_{dataset_name}.csv'\n",
    "            comparison_df.to_csv(comparison_filename, index=False)\n",
    "            print(f\"  Comparison table saved to: {comparison_filename}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_visualizations(results_df, dataset_name, X):\n",
    "    \n",
    "    standard_results = results_df[results_df['method'] == 'Standard_KMeans']\n",
    "    fuzzy_results = results_df[results_df['method'] == 'Fuzzy_Equivalence']\n",
    "    successful_fuzzy = fuzzy_results[fuzzy_results['n_clusters_found'] > 0].copy()\n",
    "    \n",
    "    if len(successful_fuzzy) == 0 or X.shape[1] < 2:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📊 Creating visualizations for {dataset_name}...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    if len(standard_results) > 0:\n",
    "        ax = axes[0]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=int(standard_results.iloc[0]['n_clusters_found']), \n",
    "                       random_state=42, n_init=10)\n",
    "        kmeans_labels = kmeans.fit_predict(X_scaled[:, :2])\n",
    "        \n",
    "        scatter = ax.scatter(X_scaled[:, 0], X_scaled[:, 1], \n",
    "                           c=kmeans_labels, \n",
    "                           cmap='viridis', \n",
    "                           s=30, \n",
    "                           alpha=0.7,\n",
    "                           edgecolors='w',\n",
    "                           linewidth=0.5)\n",
    "        \n",
    "        std_row = standard_results.iloc[0]\n",
    "        title = f\"Standard KMeans\\n\"\n",
    "        title += f\"Silhouette: {std_row['silhouette_score']:.3f}\\n\"\n",
    "        title += f\"DB: {std_row['davies_bouldin_score']:.3f}\\n\"\n",
    "        title += f\"CH: {std_row['calinski_harabasz_score']:.1f}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.set_xlabel('Feature 1 (scaled)')\n",
    "        ax.set_ylabel('Feature 2 (scaled)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    top_fuzzy = successful_fuzzy.sort_values('silhouette_score', ascending=False).head(3)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_fuzzy.iterrows()):\n",
    "        ax = axes[idx + 1]  # +1 because axes[0] is for standard KMeans\n",
    "        \n",
    "        try:\n",
    "            model = FuzzyEquivalenceKMeans(\n",
    "                n_clusters=int(row['n_clusters_found']),\n",
    "                E=row['E'],\n",
    "                A=row['A'],\n",
    "                p=row['p'] if pd.notnull(row['p']) else 1,\n",
    "                max_iter=100,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            labels = model.fit_predict(X[:, :2])\n",
    "            \n",
    "            scatter = ax.scatter(X[:, 0], X[:, 1], \n",
    "                               c=labels, \n",
    "                               cmap='viridis', \n",
    "                               s=30, \n",
    "                               alpha=0.7,\n",
    "                               edgecolors='w',\n",
    "                               linewidth=0.5)\n",
    "            \n",
    "            title = f\"{row['combination']}\\n\"\n",
    "            title += f\"Silhouette: {row['silhouette_score']:.3f}\\n\"\n",
    "            title += f\"DB: {row['davies_bouldin_score']:.3f}\\n\"\n",
    "            title += f\"CH: {row['calinski_harabasz_score']:.1f}\"\n",
    "            \n",
    "            ax.set_title(title, fontsize=10)\n",
    "            ax.set_xlabel('Feature 1')\n",
    "            ax.set_ylabel('Feature 2')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"{row['combination']}\\nSilhouette: {row['silhouette_score']:.3f}\\nError: {str(e)[:50]}\",\n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=9)\n",
    "            ax.set_title(row['combination'], fontsize=10)\n",
    "    \n",
    "    plt.suptitle(f'Clustering Comparison for {dataset_name}\\nStandard KMeans vs Top 3 Fuzzy Methods', \n",
    "                fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs('results/plots', exist_ok=True)\n",
    "    plot_filename = f'results/plots/comparison_{dataset_name}.png'\n",
    "    plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"  Visualization saved to: {plot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "df73a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FUZZY EQUIVALENCE K-MEANS COMPREHENSIVE TESTING\n",
      "================================================================================\n",
      "\n",
      "📂 LOADING DATASETS...\n",
      "Loading sklearn datasets...\n",
      "Generating synthetic datasets...\n",
      "\n",
      "Note: UCI datasets will be loaded if files exist in 'data/' folder\n",
      "Loading Wholesale_Customers from data/Wholesale_customers.csv...\n",
      "  ✓ Loaded: 440 samples, 6 features\n",
      "Loading Heart_Failure from data/heart_failure_clinical_records.csv...\n",
      "  ✓ Loaded: 299 samples, 12 features\n",
      "Loading Seeds from data/seeds_dataset.csv...\n",
      "  ✓ Loaded: 209 samples, 0 features\n",
      "Loading Absenteeism from data/Absenteeism_at_work.csv...\n",
      "  ✓ Loaded: 200 samples, 21 features\n",
      "\n",
      "✅ Total datasets to test: 10\n",
      "  Iris: 150 samples, 4 features, 3 clusters\n",
      "  Wine: 178 samples, 13 features, 3 clusters\n",
      "  Breast_Cancer: 569 samples, 30 features, 2 clusters\n",
      "  Blobs: 300 samples, 2 features, 4 clusters\n",
      "  Moons: 300 samples, 2 features, 2 clusters\n",
      "  Circles: 300 samples, 2 features, 2 clusters\n",
      "  Wholesale_Customers: 440 samples, 6 features, 3 clusters\n",
      "  Heart_Failure: 299 samples, 12 features, 2 clusters\n",
      "  Seeds: 209 samples, 0 features, 3 clusters\n",
      "  Absenteeism: 200 samples, 21 features, 4 clusters\n",
      "\n",
      "================================================================================\n",
      "RUNNING TESTS...\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Iris\n",
      "Shape: (150, 4), Clusters: 3\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.4599\n",
      "     Davies-Bouldin: 0.8336\n",
      "     Calinski-Harabasz: 241.9044\n",
      "     Inertia: 139.8205\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 8\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 5\n",
      "Converged at iteration 9\n",
      "Converged at iteration 8\n",
      "Converged at iteration 7\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 8\n",
      "Converged at iteration 2\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 5\n",
      "Converged at iteration 14\n",
      "Converged at iteration 12\n",
      "Converged at iteration 6\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 10\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 6\n",
      "Converged at iteration 4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 8\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Iris\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.4599\n",
      "  Best Fuzzy: 0.5210 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +13.27%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 0.8336\n",
      "  Best Fuzzy: 0.5892 (E_FD_R_A2_p0.1)\n",
      "  ✅ Fuzzy better by: +29.32%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 241.9044\n",
      "  Best Fuzzy: 398.4264 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +64.70%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 2/55 methods\n",
      "  Davies-Bouldin: 9/55 methods\n",
      "  Calinski-Harabasz: 3/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Iris\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.4599\n",
      "  Davies-Bouldin Score: 0.8336\n",
      "  Calinski-Harabasz Score: 241.9044\n",
      "  Inertia (WCSS): 139.8205\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.5210\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +13.27%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.5892\n",
      "    Combination: E_FD_R_A2_p0.1\n",
      "    Parameters: E=E_FD_R, A=A2, p=0.1\n",
      "    vs Standard KMeans: +29.32% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 398.4264\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +64.70%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.2038\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: 109.7\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Iris.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Iris.csv\n",
      "  Comparison table saved to: results/comparison_Iris.csv\n",
      "\n",
      "📊 Creating visualizations for Iris...\n",
      "Converged at iteration 3\n",
      "Converged at iteration 12\n",
      "Converged at iteration 12\n",
      "  Visualization saved to: results/plots/comparison_Iris.png\n",
      "\n",
      "✓ Completed testing for Iris\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Wine\n",
      "Shape: (178, 13), Clusters: 3\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.2849\n",
      "     Davies-Bouldin: 1.3892\n",
      "     Calinski-Harabasz: 70.9400\n",
      "     Inertia: 1277.9285\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 12\n",
      "Converged at iteration 7\n",
      "Converged at iteration 9\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 9\n",
      "Converged at iteration 12\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 11\n",
      "Converged at iteration 11\n",
      "Converged at iteration 14\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 14\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 9\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 12\n",
      "Converged at iteration 9\n",
      "Converged at iteration 10\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 13\n",
      "Converged at iteration 6\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Wine\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.2849\n",
      "  Best Fuzzy: 0.5609 (E_4_A4)\n",
      "  ✅ Fuzzy better by: +96.91%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 1.3892\n",
      "  Best Fuzzy: 0.0456 (E_4_A4)\n",
      "  ✅ Fuzzy better by: +96.71%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 70.9400\n",
      "  Best Fuzzy: 791.6830 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +1015.99%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 9/52 methods\n",
      "  Davies-Bouldin: 18/52 methods\n",
      "  Calinski-Harabasz: 40/52 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Wine\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 52\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.2849\n",
      "  Davies-Bouldin Score: 1.3892\n",
      "  Calinski-Harabasz Score: 70.9400\n",
      "  Inertia (WCSS): 1277.9285\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.5609\n",
      "    Combination: E_4_A4\n",
      "    Parameters: E=E_4, A=A4, p=nan\n",
      "    vs Standard KMeans: +96.91%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.0456\n",
      "    Combination: E_4_A4\n",
      "    Parameters: E=E_4, A=A4, p=nan\n",
      "    vs Standard KMeans: +96.71% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 791.6830\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +1015.99%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.1488\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: 120.8\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Wine.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Wine.csv\n",
      "  Comparison table saved to: results/comparison_Wine.csv\n",
      "\n",
      "📊 Creating visualizations for Wine...\n",
      "Reached maximum iterations (100)\n",
      "Converged at iteration 6\n",
      "Reached maximum iterations (100)\n",
      "  Visualization saved to: results/plots/comparison_Wine.png\n",
      "\n",
      "✓ Completed testing for Wine\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Breast_Cancer\n",
      "Shape: (569, 30), Clusters: 2\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.3434\n",
      "     Davies-Bouldin: 1.3205\n",
      "     Calinski-Harabasz: 267.6917\n",
      "     Inertia: 11595.5266\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 8\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 8\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Breast_Cancer\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.3434\n",
      "  Best Fuzzy: 0.7408 (E_FD_R_A2_p0.1)\n",
      "  ✅ Fuzzy better by: +115.73%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 1.3205\n",
      "  Best Fuzzy: 0.0090 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +99.32%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 267.6917\n",
      "  Best Fuzzy: 1398.6395 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +422.48%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 18/55 methods\n",
      "  Davies-Bouldin: 29/55 methods\n",
      "  Calinski-Harabasz: 49/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Breast_Cancer\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.3434\n",
      "  Davies-Bouldin Score: 1.3205\n",
      "  Calinski-Harabasz Score: 267.6917\n",
      "  Inertia (WCSS): 11595.5266\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.7408\n",
      "    Combination: E_FD_R_A2_p0.1\n",
      "    Parameters: E=E_FD_R, A=A2, p=0.1\n",
      "    vs Standard KMeans: +115.73%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.0090\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +99.32% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 1398.6395\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +422.48%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.2369\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: 612.5\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Breast_Cancer.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Breast_Cancer.csv\n",
      "  Comparison table saved to: results/comparison_Breast_Cancer.csv\n",
      "\n",
      "📊 Creating visualizations for Breast_Cancer...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Visualization saved to: results/plots/comparison_Breast_Cancer.png\n",
      "\n",
      "✓ Completed testing for Breast_Cancer\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Blobs\n",
      "Shape: (300, 2), Clusters: 4\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.7975\n",
      "     Davies-Bouldin: 0.2811\n",
      "     Calinski-Harabasz: 3290.7373\n",
      "     Inertia: 17.4662\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 6\n",
      "Converged at iteration 7\n",
      "Converged at iteration 6\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Converged at iteration 14\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 13\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 13\n",
      "Converged at iteration 16\n",
      "Converged at iteration 14\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 6\n",
      "Converged at iteration 4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Converged at iteration 12\n",
      "Converged at iteration 6\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Converged at iteration 4\n",
      "Converged at iteration 12\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Converged at iteration 9\n",
      "Converged at iteration 15\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 10\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 5\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Converged at iteration 4\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Blobs\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.7975\n",
      "  Best Fuzzy: 0.7206 (E_FD_R_A4)\n",
      "  ❌ Standard better or equal\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 0.2811\n",
      "  Best Fuzzy: 0.3517 (E_FD_R_A4)\n",
      "  ❌ Standard better or equal\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 3290.7373\n",
      "  Best Fuzzy: 1951.8316 (E_FD_R_A4)\n",
      "  ❌ Standard better or equal\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 0/55 methods\n",
      "  Davies-Bouldin: 0/55 methods\n",
      "  Calinski-Harabasz: 0/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Blobs\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.7975\n",
      "  Davies-Bouldin Score: 0.2811\n",
      "  Calinski-Harabasz Score: 3290.7373\n",
      "  Inertia (WCSS): 17.4662\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.7206\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: -9.64%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.3517\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: -25.10% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 1951.8316\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: -40.69%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.2138\n",
      "  Average Davies-Bouldin Score: 1.4113\n",
      "  Average Calinski-Harabasz Score: 210.9\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Blobs.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Blobs.csv\n",
      "  Comparison table saved to: results/comparison_Blobs.csv\n",
      "\n",
      "📊 Creating visualizations for Blobs...\n",
      "Converged at iteration 3\n",
      "Converged at iteration 6\n",
      "Converged at iteration 7\n",
      "  Visualization saved to: results/plots/comparison_Blobs.png\n",
      "\n",
      "✓ Completed testing for Blobs\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Moons\n",
      "Shape: (300, 2), Clusters: 2\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.4910\n",
      "     Davies-Bouldin: 0.8064\n",
      "     Calinski-Harabasz: 409.6071\n",
      "     Inertia: 252.6826\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Moons\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.4910\n",
      "  Best Fuzzy: 0.8064 (E_4_A4)\n",
      "  ✅ Fuzzy better by: +64.23%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 0.8064\n",
      "  Best Fuzzy: 0.0975 (E_4_A4)\n",
      "  ✅ Fuzzy better by: +87.91%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 409.6071\n",
      "  Best Fuzzy: 1540.9124 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +276.19%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 12/55 methods\n",
      "  Davies-Bouldin: 25/55 methods\n",
      "  Calinski-Harabasz: 17/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Moons\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.4910\n",
      "  Davies-Bouldin Score: 0.8064\n",
      "  Calinski-Harabasz Score: 409.6071\n",
      "  Inertia (WCSS): 252.6826\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.8064\n",
      "    Combination: E_4_A4\n",
      "    Parameters: E=E_4, A=A4, p=nan\n",
      "    vs Standard KMeans: +64.23%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.0975\n",
      "    Combination: E_4_A4\n",
      "    Parameters: E=E_4, A=A4, p=nan\n",
      "    vs Standard KMeans: +87.91% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 1540.9124\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +276.19%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.3548\n",
      "  Average Davies-Bouldin Score: 0.9128\n",
      "  Average Calinski-Harabasz Score: 397.0\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Moons.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Moons.csv\n",
      "  Comparison table saved to: results/comparison_Moons.csv\n",
      "\n",
      "📊 Creating visualizations for Moons...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Visualization saved to: results/plots/comparison_Moons.png\n",
      "\n",
      "✓ Completed testing for Moons\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Circles\n",
      "Shape: (300, 2), Clusters: 2\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.3532\n",
      "     Davies-Bouldin: 1.1752\n",
      "     Calinski-Harabasz: 174.9430\n",
      "     Inertia: 378.0582\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Circles\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.3532\n",
      "  Best Fuzzy: 0.6135 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +73.69%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 1.1752\n",
      "  Best Fuzzy: 0.1893 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +83.90%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 174.9430\n",
      "  Best Fuzzy: 1505.6307 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +760.64%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 10/55 methods\n",
      "  Davies-Bouldin: 37/55 methods\n",
      "  Calinski-Harabasz: 49/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Circles\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.3532\n",
      "  Davies-Bouldin Score: 1.1752\n",
      "  Calinski-Harabasz Score: 174.9430\n",
      "  Inertia (WCSS): 378.0582\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.6135\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +73.69%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.1893\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +83.90% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 1505.6307\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +760.64%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.2215\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: 395.8\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Circles.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Circles.csv\n",
      "  Comparison table saved to: results/comparison_Circles.csv\n",
      "\n",
      "📊 Creating visualizations for Circles...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Visualization saved to: results/plots/comparison_Circles.png\n",
      "\n",
      "✓ Completed testing for Circles\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Wholesale_Customers\n",
      "Shape: (440, 6), Clusters: 3\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.5483\n",
      "     Davies-Bouldin: 0.9279\n",
      "     Calinski-Harabasz: 140.1352\n",
      "     Inertia: 1608.4311\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 12\n",
      "Converged at iteration 12\n",
      "Converged at iteration 2\n",
      "Converged at iteration 9\n",
      "Converged at iteration 3\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 6\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 6\n",
      "Converged at iteration 8\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Converged at iteration 8\n",
      "Converged at iteration 8\n",
      "Converged at iteration 2\n",
      "Converged at iteration 9\n",
      "Converged at iteration 3\n",
      "Converged at iteration 2\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 6\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 11\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Reached maximum iterations (200)\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Wholesale_Customers\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.5483\n",
      "  Best Fuzzy: 0.9418 (E_FD_R_A2_p0.1)\n",
      "  ✅ Fuzzy better by: +71.77%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 0.9279\n",
      "  Best Fuzzy: 0.1382 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +85.11%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 140.1352\n",
      "  Best Fuzzy: 6133.0505 (E_FD_R_A4)\n",
      "  ✅ Fuzzy better by: +4276.52%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 21/43 methods\n",
      "  Davies-Bouldin: 22/43 methods\n",
      "  Calinski-Harabasz: 41/43 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Wholesale_Customers\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 43\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.5483\n",
      "  Davies-Bouldin Score: 0.9279\n",
      "  Calinski-Harabasz Score: 140.1352\n",
      "  Inertia (WCSS): 1608.4311\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.9418\n",
      "    Combination: E_FD_R_A2_p0.1\n",
      "    Parameters: E=E_FD_R, A=A2, p=0.1\n",
      "    vs Standard KMeans: +71.77%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.1382\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +85.11% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: 6133.0505\n",
      "    Combination: E_FD_R_A4\n",
      "    Parameters: E=E_FD_R, A=A4, p=nan\n",
      "    vs Standard KMeans: +4276.52%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.4595\n",
      "  Average Davies-Bouldin Score: 1.8017\n",
      "  Average Calinski-Harabasz Score: 389.9\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Wholesale_Customers.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Wholesale_Customers.csv\n",
      "  Comparison table saved to: results/comparison_Wholesale_Customers.csv\n",
      "\n",
      "📊 Creating visualizations for Wholesale_Customers...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "  Visualization saved to: results/plots/comparison_Wholesale_Customers.png\n",
      "\n",
      "✓ Completed testing for Wholesale_Customers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Heart_Failure\n",
      "Shape: (299, 12), Clusters: 2\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.1179\n",
      "     Davies-Bouldin: 2.6221\n",
      "     Calinski-Harabasz: 35.8947\n",
      "     Inertia: 3201.1206\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 5\n",
      "Converged at iteration 4\n",
      "Converged at iteration 5\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 4\n",
      "Converged at iteration 2\n",
      "Converged at iteration 3\n",
      "Converged at iteration 5\n",
      "Converged at iteration 3\n",
      "Converged at iteration 4\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Heart_Failure\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.1179\n",
      "  Best Fuzzy: 0.3007 (E_FD_R_A2_p4.0)\n",
      "  ✅ Fuzzy better by: +155.14%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 2.6221\n",
      "  Best Fuzzy: 0.0000 (E_LK_A4)\n",
      "  ✅ Fuzzy better by: +100.00%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 35.8947\n",
      "  Best Fuzzy: inf (E_LK_A4)\n",
      "  ✅ Fuzzy better by: +inf%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 33/55 methods\n",
      "  Davies-Bouldin: 49/55 methods\n",
      "  Calinski-Harabasz: 49/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Heart_Failure\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.1179\n",
      "  Davies-Bouldin Score: 2.6221\n",
      "  Calinski-Harabasz Score: 35.8947\n",
      "  Inertia (WCSS): 3201.1206\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.3007\n",
      "    Combination: E_FD_R_A2_p4.0\n",
      "    Parameters: E=E_FD_R, A=A2, p=4.0\n",
      "    vs Standard KMeans: +155.14%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.0000\n",
      "    Combination: E_LK_A4\n",
      "    Parameters: E=E_LK, A=A4, p=nan\n",
      "    vs Standard KMeans: +100.00% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: inf\n",
      "    Combination: E_LK_A4\n",
      "    Parameters: E=E_LK, A=A4, p=nan\n",
      "    vs Standard KMeans: +inf%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.1118\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: inf\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Heart_Failure.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Heart_Failure.csv\n",
      "  Comparison table saved to: results/comparison_Heart_Failure.csv\n",
      "\n",
      "📊 Creating visualizations for Heart_Failure...\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "Converged at iteration 3\n",
      "  Visualization saved to: results/plots/comparison_Heart_Failure.png\n",
      "\n",
      "✓ Completed testing for Heart_Failure\n",
      "============================================================\n",
      "\n",
      "✗ Error testing Seeds: Found array with 0 feature(s) (shape=(209, 0)) while a minimum of 1 is required by StandardScaler.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Testing dataset: Absenteeism\n",
      "Shape: (200, 21), Clusters: 4\n",
      "============================================================\n",
      "Testing 60 combinations...\n",
      "\n",
      "1. Running Standard KMeans for baseline comparison...\n",
      "   Standard KMeans Results:\n",
      "     Silhouette: 0.1671\n",
      "     Davies-Bouldin: 2.0090\n",
      "     Calinski-Harabasz: 25.2112\n",
      "     Inertia: 3030.5545\n",
      "\n",
      "2. Running Fuzzy Equivalence KMeans combinations...\n",
      "Converged at iteration 18\n",
      "Converged at iteration 11\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Converged at iteration 5\n",
      "Converged at iteration 8\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "  Progress: 10/60 | Current: E_GG_A4\n",
      "Converged at iteration 7\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 13\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 11\n",
      "Converged at iteration 10\n",
      "Converged at iteration 10\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "  Progress: 20/60 | Current: E_FD_A4\n",
      "Converged at iteration 6\n",
      "Converged at iteration 10\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Converged at iteration 5\n",
      "Converged at iteration 6\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 6\n",
      "Converged at iteration 25\n",
      "Converged at iteration 9\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "  Progress: 40/60 | Current: E_FD_R_A4\n",
      "Converged at iteration 6\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 5\n",
      "Converged at iteration 16\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "  Progress: 50/60 | Current: E_4_A4\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 2\n",
      "Converged at iteration 5\n",
      "Converged at iteration 6\n",
      "Converged at iteration 13\n",
      "Reached maximum iterations (200)\n",
      "Converged at iteration 7\n",
      "Converged at iteration 5\n",
      "  Progress: 60/60 | Current: E_6_A4\n",
      "\n",
      "✓ Completed 61 runs for Absenteeism\n",
      "  - Standard KMeans: 1 run\n",
      "  - Fuzzy Equivalence: 60 runs\n",
      "\n",
      "============================================================\n",
      "COMPARISON ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Standard KMeans vs Best Fuzzy Equivalence:\n",
      "--------------------------------------------------\n",
      "\n",
      "Silhouette Score:\n",
      "  Standard KMeans: 0.1671\n",
      "  Best Fuzzy: 0.4200 (E_LK_A4)\n",
      "  ✅ Fuzzy better by: +151.29%\n",
      "\n",
      "Davies-Bouldin Score (lower is better):\n",
      "  Standard KMeans: 2.0090\n",
      "  Best Fuzzy: 0.0000 (E_LK_A4)\n",
      "  ✅ Fuzzy better by: +100.00%\n",
      "\n",
      "Calinski-Harabasz Score:\n",
      "  Standard KMeans: 25.2112\n",
      "  Best Fuzzy: inf (E_LK_A4)\n",
      "  ✅ Fuzzy better by: +inf%\n",
      "\n",
      "Summary of fuzzy methods beating standard:\n",
      "  Silhouette: 13/55 methods\n",
      "  Davies-Bouldin: 49/55 methods\n",
      "  Calinski-Harabasz: 49/55 methods\n",
      "\n",
      "============================================================\n",
      "ANALYSIS FOR Absenteeism\n",
      "============================================================\n",
      "\n",
      "METHODS SUMMARY:\n",
      "  Standard KMeans: 1 run\n",
      "  Fuzzy Equivalence: 60 runs\n",
      "  Successful fuzzy runs: 55\n",
      "\n",
      "STANDARD KMEANS RESULTS:\n",
      "  Silhouette Score: 0.1671\n",
      "  Davies-Bouldin Score: 2.0090\n",
      "  Calinski-Harabasz Score: 25.2112\n",
      "  Inertia (WCSS): 3030.5545\n",
      "\n",
      "BEST FUZZY EQUIVALENCE RESULTS:\n",
      "\n",
      "  Best Silhouette Score: 0.4200\n",
      "    Combination: E_LK_A4\n",
      "    Parameters: E=E_LK, A=A4, p=nan\n",
      "    vs Standard KMeans: +151.29%\n",
      "\n",
      "  Best Davies-Bouldin Score: 0.0000\n",
      "    Combination: E_LK_A4\n",
      "    Parameters: E=E_LK, A=A4, p=nan\n",
      "    vs Standard KMeans: +100.00% improvement\n",
      "\n",
      "  Best Calinski-Harabasz Score: inf\n",
      "    Combination: E_LK_A4\n",
      "    Parameters: E=E_LK, A=A4, p=nan\n",
      "    vs Standard KMeans: +inf%\n",
      "\n",
      "FUZZY METHODS SUMMARY STATISTICS:\n",
      "  Average Silhouette Score: 0.1380\n",
      "  Average Davies-Bouldin Score: inf\n",
      "  Average Calinski-Harabasz Score: inf\n",
      "\n",
      "💾 Saving results to CSV files...\n",
      "  Full results saved to: results/full_results_Absenteeism.csv\n",
      "  Top 10 fuzzy methods saved to: results/top10_fuzzy_Absenteeism.csv\n",
      "  Comparison table saved to: results/comparison_Absenteeism.csv\n",
      "\n",
      "📊 Creating visualizations for Absenteeism...\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "Converged at iteration 2\n",
      "  Visualization saved to: results/plots/comparison_Absenteeism.png\n",
      "\n",
      "✓ Completed testing for Absenteeism\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "COMBINING ALL RESULTS...\n",
      "================================================================================\n",
      "✅ All results combined and saved to: results/ALL_DATASETS_COMBINED.csv\n",
      "\n",
      "📈 CREATING GLOBAL SUMMARY...\n",
      "✅ Global summary saved to: results/GLOBAL_SUMMARY.csv\n",
      "\n",
      "📊 GLOBAL STATISTICS:\n",
      "  Total datasets tested: 9\n",
      "  Total successful runs: 489\n",
      "  Average silhouette across datasets: 0.2351\n",
      "\n",
      "🏆 MOST SUCCESSFUL FUZZY EQUIVALENCE FUNCTIONS:\n",
      "  E_FD_R: best on 5 datasets\n",
      "  E_4: best on 2 datasets\n",
      "  Euclidean: best on 1 datasets\n",
      "  E_LK: best on 1 datasets\n",
      "\n",
      "🏆 MOST SUCCESSFUL AGGREGATION FUNCTIONS:\n",
      "  A4: best on 5 datasets\n",
      "  A2: best on 3 datasets\n",
      "  Mean: best on 1 datasets\n",
      "\n",
      "================================================================================\n",
      "✅ TESTING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "All results saved in the 'results/' folder:\n",
      "  - Individual dataset results: results/full_results_*.csv\n",
      "  - Top 10 summaries: results/summary_top10_*.csv\n",
      "  - Best results: results/best_results_*.csv\n",
      "  - Visualizations: results/plots/*.png\n",
      "  - Combined results: results/ALL_DATASETS_COMBINED.csv\n",
      "  - Global summary: results/GLOBAL_SUMMARY.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FUZZY EQUIVALENCE K-MEANS COMPREHENSIVE TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📂 LOADING DATASETS...\")\n",
    "datasets = load_all_datasets()\n",
    "\n",
    "uci_datasets = load_uci_datasets()\n",
    "datasets.update(uci_datasets)\n",
    "\n",
    "print(f\"\\n✅ Total datasets to test: {len(datasets)}\")\n",
    "for name, info in datasets.items():\n",
    "    print(f\"  {name}: {info['X'].shape[0]} samples, {info['X'].shape[1]} features, {info['n_clusters']} clusters\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "test_params = {\n",
    "    'max_iter': 200,\n",
    "    'random_state': 42,\n",
    "    'p_values': [0.1, 1, 4]\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RUNNING TESTS...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for dataset_name, dataset_info in datasets.items():\n",
    "    try:\n",
    "        X = dataset_info['X']\n",
    "        n_clusters = dataset_info['n_clusters']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        results_df = run_all_combinations_on_dataset(\n",
    "            X=X_scaled,\n",
    "            dataset_name=dataset_name,\n",
    "            n_clusters=n_clusters,\n",
    "            max_iter=test_params['max_iter'],\n",
    "            random_state=test_params['random_state'],\n",
    "            p_values=test_params['p_values']\n",
    "        )\n",
    "\n",
    "        successful = analyze_and_save_results(results_df, dataset_name)\n",
    "    \n",
    "        if X.shape[1] >= 2:\n",
    "            create_visualizations(results_df, dataset_name, X_scaled[:, :2])\n",
    "        \n",
    "        all_results.append(results_df)\n",
    "        \n",
    "        print(f\"\\n✓ Completed testing for {dataset_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error testing {dataset_name}: {str(e)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        continue\n",
    "\n",
    "if all_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMBINING ALL RESULTS...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    combined_filename = 'results/ALL_DATASETS_COMBINED.csv'\n",
    "    combined_results.to_csv(combined_filename, index=False)\n",
    "    print(f\"✅ All results combined and saved to: {combined_filename}\")\n",
    "    print(f\"\\n📈 CREATING GLOBAL SUMMARY...\")\n",
    "    \n",
    "    summary_data = []\n",
    "    for dataset_name in datasets.keys():\n",
    "        dataset_results = combined_results[combined_results['dataset'] == dataset_name]\n",
    "        successful = dataset_results[dataset_results['n_clusters_found'] > 0]\n",
    "        \n",
    "        if len(successful) > 0:\n",
    "            # Get best method by silhouette score\n",
    "            best_row = successful.loc[successful['silhouette_score'].idxmax()]\n",
    "            \n",
    "            summary_data.append({\n",
    "                'dataset': dataset_name,\n",
    "                'samples': datasets[dataset_name]['X'].shape[0],\n",
    "                'features': datasets[dataset_name]['X'].shape[1],\n",
    "                'clusters': datasets[dataset_name]['n_clusters'],\n",
    "                'best_silhouette': best_row['silhouette_score'],\n",
    "                'best_combination': best_row['combination'],\n",
    "                'best_E': best_row['E'],\n",
    "                'best_A': best_row['A'],\n",
    "                'best_p': best_row['p'],\n",
    "                'best_db': successful['davies_bouldin_score'].min(),\n",
    "                'best_ch': successful['calinski_harabasz_score'].max(),\n",
    "                'avg_silhouette': successful['silhouette_score'].mean(),\n",
    "                'avg_db': successful['davies_bouldin_score'].mean(),\n",
    "                'avg_ch': successful['calinski_harabasz_score'].mean(),\n",
    "                'successful_runs': len(successful),\n",
    "                'total_runs': len(dataset_results)\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_filename = 'results/GLOBAL_SUMMARY.csv'\n",
    "        summary_df.to_csv(summary_filename, index=False)\n",
    "        print(f\"✅ Global summary saved to: {summary_filename}\")\n",
    "        \n",
    "        print(f\"\\n📊 GLOBAL STATISTICS:\")\n",
    "        print(f\"  Total datasets tested: {len(summary_df)}\")\n",
    "        print(f\"  Total successful runs: {summary_df['successful_runs'].sum()}\")\n",
    "        print(f\"  Average silhouette across datasets: {summary_df['avg_silhouette'].mean():.4f}\")\n",
    "        \n",
    "        print(f\"\\n🏆 MOST SUCCESSFUL FUZZY EQUIVALENCE FUNCTIONS:\")\n",
    "        E_counts = summary_df['best_E'].value_counts()\n",
    "        for E, count in E_counts.items():\n",
    "            print(f\"  {E}: best on {count} datasets\")\n",
    "        \n",
    "        print(f\"\\n🏆 MOST SUCCESSFUL AGGREGATION FUNCTIONS:\")\n",
    "        A_counts = summary_df['best_A'].value_counts()\n",
    "        for A, count in A_counts.items():\n",
    "            print(f\"  {A}: best on {count} datasets\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"✅ TESTING COMPLETE!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nAll results saved in the 'results/' folder:\")\n",
    "    print(\"  - Individual dataset results: results/full_results_*.csv\")\n",
    "    print(\"  - Top 10 summaries: results/summary_top10_*.csv\")\n",
    "    print(\"  - Best results: results/best_results_*.csv\")\n",
    "    print(\"  - Visualizations: results/plots/*.png\")\n",
    "    print(\"  - Combined results: results/ALL_DATASETS_COMBINED.csv\")\n",
    "    print(\"  - Global summary: results/GLOBAL_SUMMARY.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠ No results were generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9b14194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "absenteeism = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "absenteeism = absenteeism[absenteeism['dataset'] == 'Absenteeism']\n",
    "absenteeism = absenteeism[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "                           'calinski_harabasz_score', 'n_clusters_found']]\n",
    "absenteeism['davies_bouldin_score'] = absenteeism['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "absenteeism['calinski_harabasz_score'] = absenteeism['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "absenteeism_heatmap = absenteeism.style\n",
    "absenteeism_heatmap = absenteeism_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "absenteeism_heatmap = absenteeism_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(absenteeism_heatmap, 'results/plots/Absenteeism_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6d8b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "heart_failure = heart_failure[heart_failure['dataset'] == 'Heart_Failure']\n",
    "heart_failure = heart_failure[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "                             'calinski_harabasz_score', 'n_clusters_found']]\n",
    "heart_failure['davies_bouldin_score'] = heart_failure['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "heart_failure['calinski_harabasz_score'] = heart_failure['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "heart_failure_heatmap = heart_failure.style\n",
    "heart_failure_heatmap = heart_failure_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "heart_failure_heatmap = heart_failure_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(heart_failure_heatmap, 'results/plots/Heart_Failure_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "02eea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholesale_customers = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "wholesale_customers = wholesale_customers[wholesale_customers['dataset'] == 'Wholesale_Customers']\n",
    "wholesale_customers = wholesale_customers[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "                                         'calinski_harabasz_score', 'n_clusters_found']]\n",
    "wholesale_customers['davies_bouldin_score'] = wholesale_customers['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "wholesale_customers['calinski_harabasz_score'] = wholesale_customers['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "wholesale_customers_heatmap = wholesale_customers.style\n",
    "wholesale_customers_heatmap = wholesale_customers_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "wholesale_customers_heatmap = wholesale_customers_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(wholesale_customers_heatmap, 'results/plots/Wholesale_Customers_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e4a0de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "circles = circles[circles['dataset'] == 'Circles']\n",
    "circles = circles[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "                 'calinski_harabasz_score', 'n_clusters_found']]\n",
    "circles['davies_bouldin_score'] = circles['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "circles['calinski_harabasz_score'] = circles['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "circles_heatmap = circles.style\n",
    "circles_heatmap = circles_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "circles_heatmap = circles_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(circles_heatmap, 'results/plots/Circles_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1a9de47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moons = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "moons = moons[moons['dataset'] == 'Moons']\n",
    "moons = moons[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "               'calinski_harabasz_score', 'n_clusters_found']]\n",
    "moons['davies_bouldin_score'] = moons['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "moons['calinski_harabasz_score'] = moons['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "moons_heatmap = moons.style\n",
    "moons_heatmap = moons_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "moons_heatmap = moons_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(moons_heatmap, 'results/plots/Moons_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "11443b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "blobs = blobs[blobs['dataset'] == 'Blobs']\n",
    "blobs = blobs[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "               'calinski_harabasz_score', 'n_clusters_found']]\n",
    "blobs['davies_bouldin_score'] = blobs['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "blobs['calinski_harabasz_score'] = blobs['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "blobs_heatmap = blobs.style\n",
    "blobs_heatmap = blobs_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "blobs_heatmap = blobs_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(blobs_heatmap, 'results/plots/Blobs_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d2d8c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "brest_cancer = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "brest_cancer = brest_cancer[brest_cancer['dataset'] == 'Breast_Cancer']\n",
    "brest_cancer = brest_cancer[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "                           'calinski_harabasz_score', 'n_clusters_found']]\n",
    "brest_cancer['davies_bouldin_score'] = brest_cancer['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "brest_cancer['calinski_harabasz_score'] = brest_cancer['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "brest_cancer_heatmap = brest_cancer.style\n",
    "brest_cancer_heatmap = brest_cancer_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "brest_cancer_heatmap = brest_cancer_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(brest_cancer_heatmap, 'results/plots/Breast_Cancer_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "973bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "wine = wine[wine['dataset'] == 'Wine']\n",
    "wine = wine[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "             'calinski_harabasz_score', 'n_clusters_found']]\n",
    "wine['davies_bouldin_score'] = wine['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "wine['calinski_harabasz_score'] = wine['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "wine_heatmap = wine.style\n",
    "wine_heatmap = wine_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "wine_heatmap = wine_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(wine_heatmap, 'results/plots/Wine_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80c3c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')\n",
    "iris = iris[iris['dataset'] == 'Iris']\n",
    "iris = iris[['combination', 'p', 'silhouette_score', 'davies_bouldin_score', \n",
    "             'calinski_harabasz_score', 'n_clusters_found']]\n",
    "iris['davies_bouldin_score'] = iris['davies_bouldin_score'].replace([np.inf, -np.inf], np.nan)\n",
    "iris['calinski_harabasz_score'] = iris['calinski_harabasz_score'].replace([np.inf, -np.inf], np.nan)\n",
    "iris_heatmap = iris.style\n",
    "iris_heatmap = iris_heatmap.background_gradient(subset=['silhouette_score', 'calinski_harabasz_score'], cmap='plasma')\n",
    "iris_heatmap = iris_heatmap.background_gradient(subset=['davies_bouldin_score'], cmap='plasma_r')\n",
    "dfi.export(iris_heatmap, 'results/plots/Iris_heatmap.png', table_conversion='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b41ac9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/ALL_DATASETS_COMBINED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3deb803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How many times each aggregation function fell in top 3 by silhouette score:\n",
      "   A4: 14 times\n",
      "   A2(p4.0): 5 times\n",
      "   A2(p0.1): 4 times\n",
      "   A2(p1.0): 2 times\n",
      "\n",
      "2. How many times each equivalence function fell in top 3 by silhouette score:\n",
      "   E_FD: 12 times\n",
      "   E_4: 4 times\n",
      "   E_LK: 3 times\n",
      "   E_GD: 3 times\n",
      "   E_3: 1 times\n",
      "   E_6: 1 times\n",
      "   E_5: 1 times\n",
      "\n",
      "3. 3 most popular pairs of aggregation and equivalence based on silhouette score:\n",
      "   1. E_FD_A4: 4 times\n",
      "   2. E_FD_A2(p4.0): 4 times\n",
      "   3. E_4_A4: 3 times\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_sc(df):\n",
    "    datasets = df['dataset'].unique()\n",
    "    \n",
    "    aggregation_top3_counts = Counter()\n",
    "    equivalence_top3_counts = Counter()\n",
    "    pair_top3_counts = Counter()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_data = df[df['dataset'] == dataset]\n",
    "        valid_scores = dataset_data.dropna(subset=['silhouette_score'])\n",
    "        sorted_data = valid_scores.sort_values('silhouette_score', ascending=False)\n",
    "        top3 = sorted_data.head(3)\n",
    "        \n",
    "        for _, row in top3.iterrows():\n",
    "            agg_func_code = row['combination'].split('_')\n",
    "\n",
    "            if agg_func_code[-1][0] == 'p':\n",
    "                agg_func = agg_func_code[-2] + '(' + agg_func_code[-1] + ')'\n",
    "            elif len(agg_func_code) == 2:\n",
    "                continue\n",
    "            else:\n",
    "                agg_func = agg_func_code[-1]\n",
    "                \n",
    "            equiv_func = row['E']\n",
    "            \n",
    "            if pd.notna(agg_func):\n",
    "                aggregation_top3_counts[agg_func] += 1\n",
    "            \n",
    "            if pd.notna(equiv_func) and equiv_func != 'Euclidean':\n",
    "                if '_R' in equiv_func:\n",
    "                    equiv_func = equiv_func.replace('_R', '')\n",
    "                equivalence_top3_counts[equiv_func] += 1\n",
    "            \n",
    "            if pd.notna(agg_func) and pd.notna(equiv_func):\n",
    "                pair = f\"{equiv_func}_{agg_func}\"\n",
    "                pair_top3_counts[pair] += 1\n",
    "    \n",
    "    return aggregation_top3_counts, equivalence_top3_counts, pair_top3_counts\n",
    "\n",
    "aggregation_counts, equivalence_counts, pair_counts = analyze_dataset_sc(df)\n",
    "\n",
    "print(\"1. How many times each aggregation function fell in top 3 by silhouette score:\")\n",
    "for agg_func, count in sorted(aggregation_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {agg_func}: {count} times\")\n",
    "\n",
    "print(\"\\n2. How many times each equivalence function fell in top 3 by silhouette score:\")\n",
    "for equiv_func, count in sorted(equivalence_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {equiv_func}: {count} times\")\n",
    "\n",
    "print(\"\\n3. 3 most popular pairs of aggregation and equivalence based on silhouette score:\")\n",
    "for i, (pair, count) in enumerate(pair_counts.most_common(3), 1):\n",
    "    print(f\"   {i}. {pair}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "34a8062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How many times each aggregation function fell in top 3 by Davies-Bouldin score:\n",
      "   A4: 22 times\n",
      "   A2(p0.1): 3 times\n",
      "   A2(p4.0): 1 times\n",
      "\n",
      "2. How many times each equivalence function fell in top 3 by Davies-Bouldin score:\n",
      "   E_FD: 8 times\n",
      "   E_LK: 6 times\n",
      "   E_4: 4 times\n",
      "   E_3: 3 times\n",
      "   E_GD: 2 times\n",
      "   E_6: 2 times\n",
      "   E_5: 1 times\n",
      "\n",
      "3. 3 most popular pairs of aggregation and equivalence based on Davies-Bouldin score:\n",
      "   1. E_FD_A4: 7 times\n",
      "   2. E_4_A4: 4 times\n",
      "   3. E_3_A4: 3 times\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_sc(df):\n",
    "    datasets = df['dataset'].unique()\n",
    "    \n",
    "    aggregation_top3_counts = Counter()\n",
    "    equivalence_top3_counts = Counter()\n",
    "    pair_top3_counts = Counter()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_data = df[df['dataset'] == dataset]\n",
    "        valid_scores = dataset_data.dropna(subset=['davies_bouldin_score'])\n",
    "        sorted_data = valid_scores.sort_values('davies_bouldin_score', ascending=True)\n",
    "        top3 = sorted_data.head(3)\n",
    "        \n",
    "        for _, row in top3.iterrows():\n",
    "            agg_func_code = row['combination'].split('_')\n",
    "\n",
    "            if agg_func_code[-1][0] == 'p':\n",
    "                agg_func = agg_func_code[-2] + '(' + agg_func_code[-1] + ')'\n",
    "            elif len(agg_func_code) == 2:\n",
    "                continue\n",
    "            else:\n",
    "                agg_func = agg_func_code[-1]\n",
    "\n",
    "            equiv_func = row['E']\n",
    "            \n",
    "            if pd.notna(agg_func):\n",
    "                aggregation_top3_counts[agg_func] += 1\n",
    "            \n",
    "            if pd.notna(equiv_func) and equiv_func != 'Euclidean':\n",
    "                if '_R' in equiv_func:\n",
    "                    equiv_func = equiv_func.replace('_R', '')\n",
    "                equivalence_top3_counts[equiv_func] += 1\n",
    "            \n",
    "            if pd.notna(agg_func) and pd.notna(equiv_func):\n",
    "                pair = f\"{equiv_func}_{agg_func}\"\n",
    "                pair_top3_counts[pair] += 1\n",
    "    \n",
    "    return aggregation_top3_counts, equivalence_top3_counts, pair_top3_counts\n",
    "\n",
    "aggregation_counts, equivalence_counts, pair_counts = analyze_dataset_sc(df)\n",
    "\n",
    "print(\"1. How many times each aggregation function fell in top 3 by Davies-Bouldin score:\")\n",
    "for agg_func, count in sorted(aggregation_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {agg_func}: {count} times\")\n",
    "\n",
    "print(\"\\n2. How many times each equivalence function fell in top 3 by Davies-Bouldin score:\")\n",
    "for equiv_func, count in sorted(equivalence_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {equiv_func}: {count} times\")\n",
    "\n",
    "print(\"\\n3. 3 most popular pairs of aggregation and equivalence based on Davies-Bouldin score:\")\n",
    "for i, (pair, count) in enumerate(pair_counts.most_common(3), 1):\n",
    "    print(f\"   {i}. {pair}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b741e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How many times each aggregation function fell in top 3 by Calinski-Harabasz score:\n",
      "   A4: 26 times\n",
      "\n",
      "2. How many times each equivalence function fell in top 3 by Calinski-Harabasz score:\n",
      "   E_FD: 13 times\n",
      "   E_LK: 6 times\n",
      "   E_4: 3 times\n",
      "   E_6: 2 times\n",
      "   E_GD: 2 times\n",
      "\n",
      "3. 3 most popular pairs of aggregation and equivalence based on Calinski-Harabasz score:\n",
      "   1. E_FD_A4: 13 times\n",
      "   2. E_LK_A4: 6 times\n",
      "   3. E_4_A4: 3 times\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_sc(df):\n",
    "    datasets = df['dataset'].unique()\n",
    "    \n",
    "    aggregation_top3_counts = Counter()\n",
    "    equivalence_top3_counts = Counter()\n",
    "    pair_top3_counts = Counter()\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_data = df[df['dataset'] == dataset]\n",
    "        valid_scores = dataset_data.dropna(subset=['calinski_harabasz_score'])\n",
    "        sorted_data = valid_scores.sort_values('calinski_harabasz_score', ascending=False)\n",
    "        top3 = sorted_data.head(3)\n",
    "        \n",
    "        for _, row in top3.iterrows():\n",
    "            agg_func_code = row['combination'].split('_')\n",
    "\n",
    "            if agg_func_code[-1][0] == 'p':\n",
    "                agg_func = agg_func_code[-2] + '(' + agg_func_code[-1] + ')'\n",
    "            elif len(agg_func_code) == 2:\n",
    "                continue\n",
    "            else:\n",
    "                agg_func = agg_func_code[-1]\n",
    "\n",
    "            equiv_func = row['E']\n",
    "            \n",
    "            if pd.notna(agg_func):\n",
    "                aggregation_top3_counts[agg_func] += 1\n",
    "            \n",
    "            if pd.notna(equiv_func) and equiv_func != 'Euclidean':\n",
    "                if '_R' in equiv_func:\n",
    "                    equiv_func = equiv_func.replace('_R', '')\n",
    "                equivalence_top3_counts[equiv_func] += 1\n",
    "            \n",
    "            if pd.notna(agg_func) and pd.notna(equiv_func):\n",
    "                pair = f\"{equiv_func}_{agg_func}\"\n",
    "                pair_top3_counts[pair] += 1\n",
    "    \n",
    "    return aggregation_top3_counts, equivalence_top3_counts, pair_top3_counts\n",
    "\n",
    "aggregation_counts, equivalence_counts, pair_counts = analyze_dataset_sc(df)\n",
    "\n",
    "print(\"1. How many times each aggregation function fell in top 3 by Calinski-Harabasz score:\")\n",
    "for agg_func, count in sorted(aggregation_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {agg_func}: {count} times\")\n",
    "\n",
    "print(\"\\n2. How many times each equivalence function fell in top 3 by Calinski-Harabasz score:\")\n",
    "for equiv_func, count in sorted(equivalence_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {equiv_func}: {count} times\")\n",
    "\n",
    "print(\"\\n3. 3 most popular pairs of aggregation and equivalence based on Calinski-Harabasz score:\")\n",
    "for i, (pair, count) in enumerate(pair_counts.most_common(3), 1):\n",
    "    print(f\"   {i}. {pair}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60dee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
